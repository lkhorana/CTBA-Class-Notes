---
title: "Pre-read Notes"
author: "Latisha Khorana"
date: "'r Sys.Date()'"
output: html_document
----
Reference: Chapter 3 & 4 from Will AI dictate the future

Chapter 3:

"The great promise of AI for humanity, if not managed well, could also be an existential threat and potential for peril."

At it's essence, ethics is about moral principles that govern our conduct and behavior, what is right and wrong. <br>

In its simplest form: 
- AI ethics is also about what is good for individuals and society, and what is not. 

AI's "behavior" is driven by data and algorithms, and bias in AI can take different forms. <br>

There are three widely accepted sources for AI biases: 
(1) data biases 
(2) algorithmic biases
(3) human or cognitive biases

Data bias- probably the biggest - and often the root source - of the three biases. 
-If the data doesn't have a good representation of the population, it is known as representation bias. 

Algorithm bias - describes "systematic and repeatable errors" in a computer system that creates unfair outcomes, such as priviledging on arbitrary group of users over others.

Another ethical challenge of AI is responsibility. 
- Regulating AI ethics is no longer optional but an imperative in order to harness the power of AI and to protect the interests of society. 

Each organization should have in place well-defined guidelines and robust frameworks constituting principles, processes, and methodologies:
(A) privacy
(B) fairness
(C) prevention of discrimination
(D) transparency
(E) explainability
(F) security
(G) compliance
(H) tools 

The fundamental principles of governance are transparency, accuracy, fairness and acountability

Explainable AI (XAI) sometimes known as interpretable AI, refers to methods and techniques that enable humans to understand the results generated by an AI algorithm, hence improving on the governance and ethical dimension of AI. <br>
AI algorithms that have traceability and transparenc in their decision-making <br>

Explainability is an intuitively appealing concept but hard to fully realise because of the complexities of advanced AI algorithms.

Four key principles of XAI are: 
(1) Explanation: systems should provide evidence or reason(s) for all output
(2) Meaningful: systems should offer explanations that are understandable to individual users
(3) Accuracy: The answer should accurately describe the system's process for generating the output. 
(4) Knowledge Limits: The system should only operate under limits or conditions for which it was designed.

Chapter 4; 
What is AI security?
It is a set of tools and techniques that leverages AI to autonomously identify any malicious behavior and takes action to defend against potential cyber-threats based on similar or previous activity.

AI can compute and analyse a trove of data and predict, identify patterns of malicious activities, indicate potential threats, send alerts, and automate countermeasures to defend and neutralise the attacks. 

AI can assist antivirus software in identifying malicious files and new forms of malware that traditional antivirus software may not be able to detect. 

Different AI algorithms can be used to detect fraud and each of them has its pros and cons. 

Distributed Denial of Service (DDoS) is one of the major methods of cyberattacks and one of the most potent hacking techniques. 

There are two primary types of DDoS attacks:
(a) spoofing attacks: where cybercriminals impersonate
(b) flooding attacks: where they send a flood of packet requests to disrupt the availability of services. 

AI and ML algorithms are predominantly used for two purposes:
1. to detect DDoS
2. to prevent DDoS
